{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-0f269ca88172>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0, Testing Accuracy 0.827\n",
      "Iter1, Testing Accuracy 0.8946\n",
      "Iter2, Testing Accuracy 0.9013\n",
      "Iter3, Testing Accuracy 0.9059\n",
      "Iter4, Testing Accuracy 0.9086\n",
      "Iter5, Testing Accuracy 0.91\n",
      "Iter6, Testing Accuracy 0.9128\n",
      "Iter7, Testing Accuracy 0.9134\n",
      "Iter8, Testing Accuracy 0.9153\n",
      "Iter9, Testing Accuracy 0.9163\n",
      "Iter10, Testing Accuracy 0.918\n",
      "Iter11, Testing Accuracy 0.9176\n",
      "Iter12, Testing Accuracy 0.9193\n",
      "Iter13, Testing Accuracy 0.9203\n",
      "Iter14, Testing Accuracy 0.9199\n",
      "Iter15, Testing Accuracy 0.9202\n",
      "Iter16, Testing Accuracy 0.9203\n",
      "Iter17, Testing Accuracy 0.9214\n",
      "Iter18, Testing Accuracy 0.921\n",
      "Iter19, Testing Accuracy 0.9221\n",
      "Iter20, Testing Accuracy 0.9213\n",
      "Iter21, Testing Accuracy 0.9218\n",
      "Iter22, Testing Accuracy 0.923\n",
      "Iter23, Testing Accuracy 0.9221\n",
      "Iter24, Testing Accuracy 0.9218\n",
      "Iter25, Testing Accuracy 0.923\n",
      "Iter26, Testing Accuracy 0.9237\n",
      "Iter27, Testing Accuracy 0.9239\n",
      "Iter28, Testing Accuracy 0.9241\n",
      "Iter29, Testing Accuracy 0.9238\n",
      "Iter30, Testing Accuracy 0.9231\n",
      "Iter31, Testing Accuracy 0.9241\n",
      "Iter32, Testing Accuracy 0.924\n",
      "Iter33, Testing Accuracy 0.9245\n",
      "Iter34, Testing Accuracy 0.9245\n",
      "Iter35, Testing Accuracy 0.9254\n",
      "Iter36, Testing Accuracy 0.9243\n",
      "Iter37, Testing Accuracy 0.9246\n",
      "Iter38, Testing Accuracy 0.9251\n",
      "Iter39, Testing Accuracy 0.9263\n",
      "Iter40, Testing Accuracy 0.9262\n",
      "Iter41, Testing Accuracy 0.9251\n",
      "Iter42, Testing Accuracy 0.9271\n",
      "Iter43, Testing Accuracy 0.9257\n",
      "Iter44, Testing Accuracy 0.926\n",
      "Iter45, Testing Accuracy 0.9261\n",
      "Iter46, Testing Accuracy 0.9262\n",
      "Iter47, Testing Accuracy 0.9264\n",
      "Iter48, Testing Accuracy 0.9274\n",
      "Iter49, Testing Accuracy 0.9268\n",
      "Iter50, Testing Accuracy 0.9276\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 参数摘要\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)  # 平均值\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)  # 标准差\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))  # 最大值\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))  # 最小值\n",
    "        tf.summary.histogram('histogram', var)  # 直方图\n",
    "        \n",
    "# 定义命名空间\n",
    "with tf.name_scope('input'):\n",
    "    # 定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='x-input')\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='y-input')\n",
    "\n",
    "with tf.name_scope('layer'):\n",
    "    # 创建一个简单的神经网络, 只有输入层和输出层\n",
    "    with tf.name_scope('wights'):\n",
    "        W = tf.Variable(tf.zeros([784, 10]), name='w')\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b = tf.Variable(tf.zeros([10]), name='b')\n",
    "        variable_summaries(b)\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(x, W) + b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    # 二次代价函数\n",
    "    # loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "with tf.name_scope('train'):\n",
    "    # 使用梯度下降\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_predition'):\n",
    "        # 结果存放在一个布尔型列表中\n",
    "        correct_predition = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))   # argmax 返回一维张量中最大值所在的位置\n",
    "    with tf.name_scope('accuracy'):\n",
    "        # 求准确率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predition, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# 合并所有的summary\n",
    "merged = tf.summary.merge_all()\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    for epoch in range(51):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            \n",
    "        writer.add_summary(summary, epoch)\n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print('Iter' + str(epoch) + ', Testing Accuracy ' + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
