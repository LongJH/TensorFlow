{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-0f269ca88172>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0, Testing Accuracy 0.9499, Learning rate 0.001\n",
      "Iter1, Testing Accuracy 0.9612, Learning rate 0.00095\n",
      "Iter2, Testing Accuracy 0.9695, Learning rate 0.0009025\n",
      "Iter3, Testing Accuracy 0.9699, Learning rate 0.000857375\n",
      "Iter4, Testing Accuracy 0.972, Learning rate 0.00081450626\n",
      "Iter5, Testing Accuracy 0.9717, Learning rate 0.0007737809\n",
      "Iter6, Testing Accuracy 0.9755, Learning rate 0.0007350919\n",
      "Iter7, Testing Accuracy 0.9769, Learning rate 0.0006983373\n",
      "Iter8, Testing Accuracy 0.978, Learning rate 0.0006634204\n",
      "Iter9, Testing Accuracy 0.9783, Learning rate 0.0006302494\n",
      "Iter10, Testing Accuracy 0.979, Learning rate 0.0005987369\n",
      "Iter11, Testing Accuracy 0.978, Learning rate 0.0005688001\n",
      "Iter12, Testing Accuracy 0.9797, Learning rate 0.0005403601\n",
      "Iter13, Testing Accuracy 0.9796, Learning rate 0.0005133421\n",
      "Iter14, Testing Accuracy 0.9805, Learning rate 0.000487675\n",
      "Iter15, Testing Accuracy 0.9798, Learning rate 0.00046329122\n",
      "Iter16, Testing Accuracy 0.98, Learning rate 0.00044012666\n",
      "Iter17, Testing Accuracy 0.9813, Learning rate 0.00041812033\n",
      "Iter18, Testing Accuracy 0.9801, Learning rate 0.00039721432\n",
      "Iter19, Testing Accuracy 0.9813, Learning rate 0.0003773536\n",
      "Iter20, Testing Accuracy 0.98, Learning rate 0.00035848594\n",
      "Iter21, Testing Accuracy 0.9813, Learning rate 0.00034056162\n",
      "Iter22, Testing Accuracy 0.9819, Learning rate 0.00032353355\n",
      "Iter23, Testing Accuracy 0.9811, Learning rate 0.00030735688\n",
      "Iter24, Testing Accuracy 0.9803, Learning rate 0.000291989\n",
      "Iter25, Testing Accuracy 0.982, Learning rate 0.00027738957\n",
      "Iter26, Testing Accuracy 0.9806, Learning rate 0.0002635201\n",
      "Iter27, Testing Accuracy 0.9816, Learning rate 0.00025034408\n",
      "Iter28, Testing Accuracy 0.9823, Learning rate 0.00023782688\n",
      "Iter29, Testing Accuracy 0.9823, Learning rate 0.00022593554\n",
      "Iter30, Testing Accuracy 0.9819, Learning rate 0.00021463877\n",
      "Iter31, Testing Accuracy 0.9818, Learning rate 0.00020390682\n",
      "Iter32, Testing Accuracy 0.9826, Learning rate 0.00019371149\n",
      "Iter33, Testing Accuracy 0.9822, Learning rate 0.0001840259\n",
      "Iter34, Testing Accuracy 0.9821, Learning rate 0.00017482461\n",
      "Iter35, Testing Accuracy 0.9821, Learning rate 0.00016608338\n",
      "Iter36, Testing Accuracy 0.9821, Learning rate 0.00015777921\n",
      "Iter37, Testing Accuracy 0.9822, Learning rate 0.00014989026\n",
      "Iter38, Testing Accuracy 0.9826, Learning rate 0.00014239574\n",
      "Iter39, Testing Accuracy 0.9823, Learning rate 0.00013527596\n",
      "Iter40, Testing Accuracy 0.9818, Learning rate 0.00012851215\n",
      "Iter41, Testing Accuracy 0.9821, Learning rate 0.00012208655\n",
      "Iter42, Testing Accuracy 0.9825, Learning rate 0.00011598222\n",
      "Iter43, Testing Accuracy 0.9815, Learning rate 0.00011018311\n",
      "Iter44, Testing Accuracy 0.9822, Learning rate 0.000104673956\n",
      "Iter45, Testing Accuracy 0.9822, Learning rate 9.944026e-05\n",
      "Iter46, Testing Accuracy 0.9819, Learning rate 9.446825e-05\n",
      "Iter47, Testing Accuracy 0.9818, Learning rate 8.974483e-05\n",
      "Iter48, Testing Accuracy 0.982, Learning rate 8.525759e-05\n",
      "Iter49, Testing Accuracy 0.9818, Learning rate 8.099471e-05\n",
      "Iter50, Testing Accuracy 0.9821, Learning rate 7.6944976e-05\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小     是否可以更优？\n",
    "batch_size = 100\n",
    "# batch_size 越小，每轮训练批次越多，准确率越高，,50：0.9199\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.Variable(0.001, dtype=tf.float32)\n",
    "\n",
    "# 创建一个简单的神经网络, 只有输入层和输出层\n",
    "W1 = tf.Variable(tf.truncated_normal([784, 500], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([500]) + 0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x, W1) + b1)\n",
    "L1_drop = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([500, 300], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([300]) + 0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop, W2) + b2)\n",
    "L2_drop = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([300, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]) + 0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L2_drop, W3) + b3)\n",
    "\n",
    "# 二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "# 交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "\n",
    "# 使用梯度下降\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "# Adam优化\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型列表中\n",
    "correct_predition = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))   # argmax 返回一维张量中最大值所在的位置\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predition, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(51):\n",
    "        sess.run(tf.assign(lr, 0.001 * (0.95 ** epoch)))    # 重新赋值 lr\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys, keep_prob: 1.0})\n",
    "            \n",
    "        learning_rate = sess.run(lr)\n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels, keep_prob: 1.0})\n",
    "        print('Iter' + str(epoch) + ', Testing Accuracy ' + str(acc) + ', Learning rate ' + str(learning_rate))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
