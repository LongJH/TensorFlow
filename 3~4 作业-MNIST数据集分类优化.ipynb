{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-0f269ca88172>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# 载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter0, Testing Accuracy 0.8256\n",
      "Iter1, Testing Accuracy 0.8908\n",
      "Iter2, Testing Accuracy 0.9011\n",
      "Iter3, Testing Accuracy 0.9059\n",
      "Iter4, Testing Accuracy 0.909\n",
      "Iter5, Testing Accuracy 0.9101\n",
      "Iter6, Testing Accuracy 0.9117\n",
      "Iter7, Testing Accuracy 0.9132\n",
      "Iter8, Testing Accuracy 0.915\n",
      "Iter9, Testing Accuracy 0.9157\n",
      "Iter10, Testing Accuracy 0.9172\n",
      "Iter11, Testing Accuracy 0.9182\n",
      "Iter12, Testing Accuracy 0.919\n",
      "Iter13, Testing Accuracy 0.9199\n",
      "Iter14, Testing Accuracy 0.9215\n",
      "Iter15, Testing Accuracy 0.9207\n",
      "Iter16, Testing Accuracy 0.9201\n",
      "Iter17, Testing Accuracy 0.9212\n",
      "Iter18, Testing Accuracy 0.9215\n",
      "Iter19, Testing Accuracy 0.9213\n",
      "Iter20, Testing Accuracy 0.9214\n",
      "Iter21, Testing Accuracy 0.9222\n",
      "Iter22, Testing Accuracy 0.9222\n",
      "Iter23, Testing Accuracy 0.9226\n",
      "Iter24, Testing Accuracy 0.9235\n",
      "Iter25, Testing Accuracy 0.9226\n",
      "Iter26, Testing Accuracy 0.9238\n",
      "Iter27, Testing Accuracy 0.923\n",
      "Iter28, Testing Accuracy 0.9232\n",
      "Iter29, Testing Accuracy 0.9235\n",
      "Iter30, Testing Accuracy 0.9233\n",
      "Iter31, Testing Accuracy 0.9249\n",
      "Iter32, Testing Accuracy 0.9238\n",
      "Iter33, Testing Accuracy 0.9243\n",
      "Iter34, Testing Accuracy 0.9249\n",
      "Iter35, Testing Accuracy 0.9252\n",
      "Iter36, Testing Accuracy 0.9255\n",
      "Iter37, Testing Accuracy 0.9256\n",
      "Iter38, Testing Accuracy 0.925\n",
      "Iter39, Testing Accuracy 0.925\n",
      "Iter40, Testing Accuracy 0.9256\n",
      "Iter41, Testing Accuracy 0.9248\n",
      "Iter42, Testing Accuracy 0.9265\n",
      "Iter43, Testing Accuracy 0.9253\n",
      "Iter44, Testing Accuracy 0.9262\n",
      "Iter45, Testing Accuracy 0.9267\n",
      "Iter46, Testing Accuracy 0.9261\n",
      "Iter47, Testing Accuracy 0.927\n",
      "Iter48, Testing Accuracy 0.9275\n",
      "Iter49, Testing Accuracy 0.9274\n",
      "Iter50, Testing Accuracy 0.9269\n",
      "Iter51, Testing Accuracy 0.9275\n",
      "Iter52, Testing Accuracy 0.9278\n",
      "Iter53, Testing Accuracy 0.9273\n",
      "Iter54, Testing Accuracy 0.9283\n",
      "Iter55, Testing Accuracy 0.9281\n",
      "Iter56, Testing Accuracy 0.9274\n",
      "Iter57, Testing Accuracy 0.9275\n",
      "Iter58, Testing Accuracy 0.9269\n",
      "Iter59, Testing Accuracy 0.928\n",
      "Iter60, Testing Accuracy 0.9274\n",
      "Iter61, Testing Accuracy 0.9278\n",
      "Iter62, Testing Accuracy 0.9277\n",
      "Iter63, Testing Accuracy 0.9278\n",
      "Iter64, Testing Accuracy 0.9283\n",
      "Iter65, Testing Accuracy 0.9283\n",
      "Iter66, Testing Accuracy 0.9286\n",
      "Iter67, Testing Accuracy 0.9278\n",
      "Iter68, Testing Accuracy 0.9278\n",
      "Iter69, Testing Accuracy 0.9275\n",
      "Iter70, Testing Accuracy 0.928\n",
      "Iter71, Testing Accuracy 0.9284\n",
      "Iter72, Testing Accuracy 0.9285\n",
      "Iter73, Testing Accuracy 0.9284\n",
      "Iter74, Testing Accuracy 0.9278\n",
      "Iter75, Testing Accuracy 0.9283\n",
      "Iter76, Testing Accuracy 0.9275\n",
      "Iter77, Testing Accuracy 0.9282\n",
      "Iter78, Testing Accuracy 0.928\n",
      "Iter79, Testing Accuracy 0.9283\n",
      "Iter80, Testing Accuracy 0.9288\n",
      "Iter81, Testing Accuracy 0.9288\n",
      "Iter82, Testing Accuracy 0.9284\n",
      "Iter83, Testing Accuracy 0.9284\n",
      "Iter84, Testing Accuracy 0.928\n",
      "Iter85, Testing Accuracy 0.9282\n",
      "Iter86, Testing Accuracy 0.9289\n",
      "Iter87, Testing Accuracy 0.9285\n",
      "Iter88, Testing Accuracy 0.9284\n",
      "Iter89, Testing Accuracy 0.9283\n",
      "Iter90, Testing Accuracy 0.9285\n",
      "Iter91, Testing Accuracy 0.9284\n",
      "Iter92, Testing Accuracy 0.929\n",
      "Iter93, Testing Accuracy 0.9287\n",
      "Iter94, Testing Accuracy 0.9283\n",
      "Iter95, Testing Accuracy 0.9287\n",
      "Iter96, Testing Accuracy 0.9281\n",
      "Iter97, Testing Accuracy 0.9285\n",
      "Iter98, Testing Accuracy 0.9287\n",
      "Iter99, Testing Accuracy 0.9279\n"
     ]
    }
   ],
   "source": [
    "# 每个批次的大小     是否可以更优？\n",
    "batch_size = 100\n",
    "# batch_size 越小，每轮训练批次越多，准确率越高，,50：0.9199\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "# 定义两个placeholder\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# 创建一个简单的神经网络, 只有输入层和输出层     是否可以更优？是否添加隐藏层？用其他激活函数？W和b的初始值？\n",
    "W = tf.Variable(tf.zeros([784, 10]))      # 本例中使用 zeros 在初始时就可以得到一个较高的分数\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x, W) + b)    # 输出层一定要使用 softmax\n",
    "\n",
    "\n",
    "# 添加一个隐藏层, 包含 40个神经元, 建得不好，效果变差\n",
    "# W_L1 = tf.Variable(tf.random_uniform([784, 40]))\n",
    "# b_L1 = tf.Variable(tf.zeros([40]))\n",
    "# L1 = tf.nn.tanh(tf.matmul(x, W_L1) + b_L1)\n",
    "# W_L2 = tf.Variable(tf.random_uniform([40, 10])) \n",
    "# b_L2 = tf.Variable(tf.zeros([10]))\n",
    "# prediction = tf.nn.softmax(tf.matmul(L1, W_L2) + b_L2)\n",
    "\n",
    "# 二次代价函数     是否可以更优？\n",
    "# loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "# 交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=prediction))\n",
    "\n",
    "# 使用梯度下降     是否可以更优？\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 结果存放在一个布尔型列表中\n",
    "correct_predition = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))   # argmax 返回一维张量中最大值所在的位置\n",
    "# 求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predition, tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(100):     # 是否可以更优？\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels})\n",
    "        print('Iter' + str(epoch) + ', Testing Accuracy ' + str(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
